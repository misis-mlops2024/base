version: '3.7'

x-airflow-common:
  &airflow-common
  build:
      context: .
      dockerfile: DockerfileAirflow
  depends_on:
    - postgres
  environment:
    - LOAD_EX=n
    - EXECUTOR=Local
    - AIRFLOW__CORE__EXECUTOR=LocalExecutor
    - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
    - AIRFLOW__WEBSERVER__SECRET_KEY=FB0o_zt4e3Ziq3LdUUO7F2Z95cvFFx16hU8jTeR1ASM=
    - AIRFLOW__CORE__FERNET_KEY=FB0o_zt4e3Ziq3LdUUO7F2Z95cvFFx16hU8jTeR1ASM=
    - AIRFLOW__CORE__LOAD_EXAMPLES=True
    - AIRFLOW__CORE__LOGGING_LEVEL=INFO
  volumes:
    - C:\Users\anana\Desktop\projs\2024\mlops_course\data\airflow\dags:/opt/airflow/dags
    - C:\Users\anana\Desktop\projs\2024\mlops_course\data\airflow\logs:/opt/airflow/logs
    - C:\Users\anana\Desktop\projs\2024\mlops_course\data\airflow\config:/opt/airflow/config
    - C:\Users\anana\Desktop\projs\2024\mlops_course\data\airflow\plugins:/opt/airflow/plugins
    - C:\Users\anana\Desktop\projs\2024\mlops_course\data\airflow\data:/opt/data
  user: "${AIRFLOW_UID:-50000}:0"
  networks:
    - frontend

services:
  postgres:
      image: postgres:9.6
      environment:
          - POSTGRES_USER=airflow
          - POSTGRES_PASSWORD=airflow
          - POSTGRES_DB=airflow
      logging:
          options:
              max-size: 10m
              max-file: "3"
      ports:
        - 5432:5432
      networks:
      - frontend

  webserver:
      << : *airflow-common
      restart: always
      depends_on:
          - airflow-init
      logging:
          options:
              max-size: 10m
              max-file: "3"
      ports:
          - 8080:8080
      command: webserver
      healthcheck:
          test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
          interval: 30s
          timeout: 30s
          retries: 3

  airflow-scheduler:
    <<: *airflow-common
    depends_on:
      - airflow-init
    command: scheduler
    restart: always

  airflow-init:
      << : *airflow-common
      entrypoint: /bin/bash
      command:
          - -c
          - (airflow users list | grep "No data found") && ( airflow db init &&
              airflow users create
                --role Admin
                --username airflow
                --password airflow
                --email airflow@airflow.com
                --firstname airflow
                --lastname airflow )
  
  prometheus:
    image: prom/prometheus:latest
    restart: unless-stopped
    volumes:
      - C:\Users\anana\Desktop\projs\2024\mlops_course\data\prometheus\prometheus.yml:/etc/prometheus/prometheus.yml
      - C:\Users\anana\Desktop\projs\2024\mlops_course\data\prometheus\data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
    ports:
      - '9090:9090'
      # - 9090
    networks:
    - frontend

  grafana:
    image: grafana/grafana-enterprise:latest
    restart: unless-stopped
    ports:
      - '3000:3000'
    networks:
    - frontend
  
  ml-model:
    image: l3lush/online_inference:v4 
    ports:
      - '80:80'
    networks:
      - frontend
    environment:
    - AWS_ACCESS_KEY_ID=YCAJE7EasWFd2LlH_j9tbt1Ar
    - AWS_SECRET_ACCESS_KEY=YCP5frOh73GPSCHB8_1OhKw7Nk259ak4wILSFhoF
    - MLFLOW_TRACKING_URI=http://89.169.171.107:8000
    - MLFLOW_S3_ENDPOINT_URL=https://storage.yandexcloud.net/

networks:
  frontend:
    driver: bridge

volumes:
  postgres-db-volume: